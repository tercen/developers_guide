# Operator development

# General workflow

Let's go through a general approach to create an operator for Tercen. 
Operators can be developed in either R or Python, and this guide will show you how to create equivalent functionality in both languages.

A more detailed walk through (a tutorial) example is outlined in the next 
section where a linear regression operator is built from scratch.

Building an operator requires the following sequential steps: 

* Design the operator
* Setup the github repository
* Setup the input projection
* Connecting to Tercen
* Testing 
* Managing input parameters
* Managing packages/dependencies
* Deploy

## Design the operator

The first step is to define our __input projection__ and __output relation__. 
In Tercen, each operator shall take as input a table and return a table. Remember:

> "__Table in, table out!__"

To understand the input table and the output table. The input table is defined 
by the data __input projection__ in Tercen and output table is what is computed 
by the operator. The output table (also called the __computed table__) is 
related to the input table by an __output relation__.  

The __input project__ is the projection in the data step which is used by 
the operator. For example a projection is composed of the `y-axis`, `x-axis`,
`row`, `col`, `color`, `label`. This input project determines what is the
structure of the data which is given to the operator. An operator which computes 
a simple `mean` would use a `y-axis`, `row`, `col` projection. This allows 
the `mean` to be computed per cell. A linear regression operator like `lm` might
use a projection with `y-axis`, `x-axis`, and `row`, `col`. This allows the `lm` 
to be computed per cell. 

The __output relation__ is the relation of the calculated output to the 
input values. For example:

* Is the relation per Cell?
* Is the relation per Column?
* Is the relation per Row? 
* Is the relation for All the data?

__Per Cell__ example : Let's say the operator used a projection with `row` and `col` and the operator calculates a `mean` which is computed for each cell (i.e. per row/col), this would be a per cell relationship.

__Per Column__ example: Let's say the operator used a project with `row` and `col` and the operator performed a clustering on the columns, this would be a column relationship.

__for All__ data example: Let's say the operator used a project with `row` and `col` and the operator calculated a total `mean` of all the data (i.e. across all rows and cols), this would be an all data relationship.

**Steps for designing the operator**

* Understand the Tercen concepts
* Look at existing operators
* Decide what variables are needed for the __input projection__
* Decide what values need to be computed and which __output relations__ have to be created

## Set up a GitHub project

All operators currently are developed on GitHub. It is required to have a 
GitHub account to develop an operator, as operator are implemented in a 
GitHub repository.

In order to get started, the easiest way is the use one of the GitHub repository
templates we have prepared:

::: {.panel-tabset}

### R

* [minimal template for R operators](https://github.com/tercen/template_R_operator_lite)
* [template for R operators](https://github.com/tercen/template_R_operator)
* [template for Shiny operators](https://github.com/tercen/template_shiny_operator)
* [template for Docker operators](https://github.com/tercen/simple_docker_operator)

### Python

* [template for Python operators](https://github.com/tercen/template_python_operator)

:::

**Steps for starting with the operator repository**

* Get a GitHub account
* Choose an operator name
* Create an operator repository on GitHub based on a template (see above)
* Clone the repo into the local development environment in Tercen Studio

## Prerequisites and Setup {-}

Before you begin, make sure you have the following prerequisites:

::: {.panel-tabset}

### R

1. Basic understanding of R programming.
2. Familiarity with Git and GitHub.
3. Tercen Studio development environment installed.
4. Access to RStudio Server at http://127.0.0.1:8787/

### Python

1. Basic understanding of Python programming.
2. Familiarity with Git and GitHub.
3. Tercen Studio development environment installed.
4. Access to VS Code Server at http://127.0.0.1:8443/

:::

Follow the instructions in the [Tercen Studio GitHub repository](https://github.com/tercen/tercen_studio) to set up the environment.

## Getting started

### Set Up a Development Data Step

* Go to Tercen local instance: http://127.0.0.1:5402/

* Create a project by clicking on __New project__

* Click on the __From git__ tab and create a new project from `https://github.com/tercen/developers_guide_project` as follows: 

<center><img src="./images/python_dev_1.png" width=700></img></center>

* This action will populate a new project that contains an example dataset (_Crabs_) and a small workflow to get started with development.

* Open the __Dev workflow__ and double click on the  __Dev data step__ to open the __crosstab__ view.

* This a an input data projection we have prepared in the purpose of developing an operator to compute the mean value of the y axis factor, per cell (i.e., the data is grouped using row and column factors). You should
see the following projection:

<center><img src="./images/python_dev_2.png" width=700></img></center>

### Set Up Environment and Install Core Requirements

::: {.panel-tabset}

### R

* Navigate to RStudio: http://127.0.0.1:8787/
* Create a new project by clicking on File > New project > Version control > Git
* Provide the URL of your GitHub repository and clone it locally
* Install required R packages using the standard install procedures:

```r
install.packages("tercen")
install.packages("dplyr")
# Install other required packages
```

### Python

* Navigate to VS Code: http://127.0.0.1:8443/
* If you open it for the first time, you might be asked to install some VS Code extensions. Accept and install the Python extensions.
* Open a terminal in VS Code Server by clicking on the terminal icon in the lower left corner. Navigate to your cloned repository directory using the `cd` command. Install the core requirements by running the following command:

```bash
pip3 install -r requirements.txt
```

:::

## Setup the input data

This can be done in your local environment or in a cloud instance of Tercen.

* Login to Tercen (either local or cloud)
* Prepare your data by defining a __cross-tab__ projection using a __data step__.
* Note that the project in the data step has URL with this pattern: `/w/workflowId/ds/stepId`, where `workflowId` and `stepId` are __unique workflow and data step identifiers__, respectively. These identifiers will be used in the next step to get data from this data step.

## Connecting to Tercen

Once you have cloned the github operator project into your local development environment and you 
have setup the Tercen data projection, we can code and test our operator locally.

### Interact with data through the API

The first thing we'll do is to interactively work with the data we have projected in the crosstab.

To do so, you can get from the data step URL the __workflow ID__ and the __data step ID__. 

::: {.panel-tabset}

### R

If you wish to test with the local version of Tercen, then you do not require 
to set the `tercen.service` system variable. 

* Load some data up in the local instance of Tercen
* Each data step has a unique`workflowId` and a `stepId` combination.

```r
library(tercen)
library(dplyr)

options("tercen.workflowId"= "8a8845f6a5eeff27ce33fd382444de88")
options("tercen.stepId"= "5191724b-3963-4e34-af58-7977cc61e5b1")

# Connect to the context
ctx <- tercenCtx()
```

___Connecting to Tercen cloud___

Additional system variable are required in order to connect to a data step in 
the Tercen cloud.

```r
options("tercen.serviceUri"= "https://tercen.com/api/v1/")
options("tercen.username"= "uuuu")
options("tercen.password"= "pppp")
```

Where `uuuu` is the username and `pppp` is the password, these are specific 
to your username and password.

### Python

Open the `main.py` file and paste the following code:

```python
from tercen.client import context as ctx
import numpy as np

tercenCtx = ctx.TercenContext(
    workflowId="YOUR_WORKFLOW_ID",
    stepId="YOUR_STEP_ID",
    username="admin", # if using the local Tercen instance
    password="admin", # if using the local Tercen instance
    serviceUri="http://tercen:5400/" # if using the local Tercen instance 
)
```

Execute this code (Shift + Enter) in the Python console after having replaced the workflow and step IDs.

:::

### Understanding the API {-}

Now that we have initialised the __Tercen context__, we can interact with the data step. Let's start by __selecting__ some data:

::: {.panel-tabset}

### R

```r
# Select y values
ctx %>% select(.y)

# Select y, column index, and row index
ctx %>% select(.y, .ci, .ri)

# Try these functions:
ctx %>% cselect()  # select column factors
ctx %>% rselect()  # select row factors
ctx %>% colors()   # get color factors
ctx %>% labels()   # get label factors
```

### Python

```python
# Select y values
tercenCtx.select(['.y'])

# Select y, column index, and row index
tercenCtx.select(['.y', '.ci', '.ri'])

# Try these functions:
tercenCtx.cselect()  # select column factors
tercenCtx.rselect()  # select row factors
tercenCtx.colors()   # get color factors
tercenCtx.labels()   # get label factors
```

:::

You can check what is available in the __Tables__ button in the crosstab. It contains the data that has been queried. You can look at it to get some inspiration. For example,
we can identify the `.y`, `.ci` (column index) and `.ri` (row index) factors that we have queried above, but more are available.

Here is a description of the most commonly used functions:

* `select()`: select any factor specified in the arguments
* `as.matrix()`: gets data from Tercen in a matrix format (rows x columns, y values being used to fill the matrix)
* `cselect()`: select column factors
* `rselect()`: select row factors
* `cnames`: get column factor names
* `rnames`: get row factor names
* `colors`: get color factor names
* `labels`: get label factor names
* `addNamespace()`: add a unique namespace (defined in the data step environment within Tercen) to variable names
* `save()`: send back an output table to Tercen

We invite you to play around and test these different functions. They are mainly designed to retrieve data from Tercen, and send back output tables. In between, you are free to compute whatever you need.

# Walkthrough example: Developing an operator

Here we will learn through a concrete example how to create an operator for Tercen. Our goal is to create an operator performing calculations on our input data. We'll show equivalent implementations in both R and Python.

## Simple mean calculation operator {-}

Let's start with a simple example that calculates the mean per cell:

::: {.panel-tabset}

### R

```r
library(tercen)
library(dplyr)

# Set up connection
options("tercen.workflowId" = "YOUR_WORKFLOW_ID")
options("tercen.stepId" = "YOUR_STEP_ID")

# Main operator code
ctx <- tercenCtx() %>%
  select(.y, .ci, .ri) %>%         # select variables of interest
  group_by(.ri, .ci) %>%           # group by row and column ("per cell")
  summarise(mean = mean(.y)) %>%   # calculate mean per cell
  ctx$addNamespace() %>%           # add namespace
  ctx$save()                       # push results back to Tercen
```

### Python

```python
from tercen.client import context as ctx
import numpy as np

# Set up connection
tercenCtx = ctx.TercenContext(
    workflowId="YOUR_WORKFLOW_ID",
    stepId="YOUR_STEP_ID",
    username="admin",
    password="admin",
    serviceUri="http://tercen:5400/"
)

# Main operator code
df = (
    tercenCtx
    .select(['.y', '.ci', '.ri'], df_lib="polars")
    .groupby(['.ci', '.ri'])
    .mean()
    .rename({".y": "mean"})
)

# Add namespace and save the computed mean per cell
df = tercenCtx.add_namespace(df)
tercenCtx.save(df)
```

:::

## Linear regression operator example {-}

Now let's create a more complex operator that performs linear regression:

### Designing the operator {-}

Here we want to perform the linear regression of the values __projected on the y axis__ against the values __projected on the x axis__, __per cell__. In this example, we will output only the intercept and the slope of the model, __per cell__. 

<center><img src="./images/R_operator_example_MODEL.png" width=500></img></center>

### Implementation {-}

::: {.panel-tabset}

### R

```r
library(tercen)
library(dplyr)

# Set up connection
options("tercen.workflowId" = "YOUR_WORKFLOW_ID")
options("tercen.stepId" = "YOUR_STEP_ID")

# Define the linear model function
do.lm <- function(df) {
  out <- data.frame(
    .ri = df$.ri[1],
    .ci = df$.ci[1],
    intercept = NaN,
    slope = NaN
  )
  
  # Try to fit linear model
  tryCatch({
    mod <- lm(.y ~ .x, data = df)
    out$intercept <- mod$coefficients[1]
    out$slope <- mod$coefficients[2]
  }, error = function(e) {
    # Keep NaN values if model fails
  })
  
  return(out)
}

# Main operator code
ctx <- tercenCtx() %>%              # Get data from the data step
  select(.x, .y, .ri, .ci) %>%     # select variables of interest
  group_by(.ri, .ci) %>%           # group by row and column ("per cell")
  do(do.lm(.)) %>%                 # do the linear model
  ctx$addNamespace() %>%           # add namespace
  ctx$save()                       # push results back to Tercen using the API
```

### Python

```python
from tercen.client import context as ctx
import numpy as np
import polars as pl
from sklearn.linear_model import LinearRegression

# Set up connection
tercenCtx = ctx.TercenContext(
    workflowId="YOUR_WORKFLOW_ID",
    stepId="YOUR_STEP_ID",
    username="admin",
    password="admin",
    serviceUri="http://tercen:5400/"
)

def do_lm(group_df):
    """Perform linear regression on a group"""
    try:
        # Get x and y values
        x = group_df['.x'].to_numpy().reshape(-1, 1)
        y = group_df['.y'].to_numpy()
        
        # Fit linear regression
        model = LinearRegression()
        model.fit(x, y)
        
        return pl.DataFrame({
            '.ri': [group_df['.ri'][0]],
            '.ci': [group_df['.ci'][0]],
            'intercept': [model.intercept_],
            'slope': [model.coef_[0]]
        })
    except:
        # Return NaN if model fails
        return pl.DataFrame({
            '.ri': [group_df['.ri'][0]],
            '.ci': [group_df['.ci'][0]],
            'intercept': [np.nan],
            'slope': [np.nan]
        })

# Main operator code
df = tercenCtx.select(['.x', '.y', '.ci', '.ri'], df_lib="polars")

# Group by cell and apply linear regression
result = (
    df.groupby(['.ci', '.ri'])
    .map_groups(do_lm)
)

# Add namespace and save
result = tercenCtx.add_namespace(result)
tercenCtx.save(result)
```

:::

## Managing input parameters

The operator has a file called `operator.json` these define the parameters which
the user can set when using your operator.

Before deploying, please think what parameters are required and modify this file.

Example `operator.json`:

```json
{
  "kind": "DataStep",
  "version": "1.0.0",
  "name": "Linear Regression",
  "description": "Performs linear regression per cell",
  "tags": ["regression", "statistics"],
  "authors": ["Your Name"],
  "urls": ["https://github.com/yourusername/your-operator"],
  "container": {
    "language": "r",
    "version": "4.0"
  },
  "properties": []
}
```

## Managing packages and dependencies

::: {.panel-tabset}

### R

The newly created operators requires the correct packages to be loaded.
Install the packages your require using the standard install procedures, we
recommend the following:

* install.packages()
* remotes::install_github()

Just before you deploy your operator, it is necessary to setup the package 
management system. A Tercen operator manages its packages using the `renv` system.
The `renv` system allows all the packages you required to be recorded 
in a `renv.lock` file.

To generate this use:

```r
renv::init() 
```

This is done before you `push` the repository to github.

### Python

If your operator requires additional Python packages, you can generate the requirements.txt file using the following command:

```bash
python3 -m tercen.util.requirements . > requirements.txt
```

Alternatively, you can manually maintain a `requirements.txt` file with your dependencies:

```txt
tercen-client>=1.0.0
numpy>=1.20.0
polars>=0.20.0
scikit-learn>=1.0.0
```

:::

## Deploy!

Once you are satisfied with your operator, you can release it.

**Document the operator**

Edit the `README.md` to describe the operator design and usage. The documentation should contain:

* A __general description__ of the operator
* A description of the __input projections__
* A description of the __output relations__

**Prepare operator testing**

It's always good to prepare some unit tests that could be ran when a new version of Tercen is released.

To include a test, you need to __create a `tests` subdirectory__ in your project directory. It must include:

* a test __input file__
* an expected __output file__
* a __`JSON` file__ containing information about the test

**Push it to your GitHub repository**

Once everything is ready, you simply need to push all the modifications to the GitHub repository that you created before.

::: {.panel-tabset}

### R

It is possible that a more secure authentication is required by GitHub
to push your changes the first time. One solution is to get a personal access token
(PAT) from GitHub from [https://github.com/settings/tokens](https://github.com/settings/tokens).
You can click on `Generate new token`, name it and select the `repo` scope. Be
mindful of the expiration setting as well.

Then, you can copy this token and paste it into RStudio after running the following
command in the R console:

```r
credentials::set_github_pat()
```

Note that the `credentials` package is installed by default in Tercen Studio.

A good introduction to Git and RStudio is [happygitwithr](https://happygitwithr.com/index.html).

### Python

Use standard Git commands to commit and push your changes:

```bash
git add .
git commit -m "Initial operator implementation"
git push origin main
```

This will trigger the Continuous Integration (CI) GitHub workflow, which performs automated tests on your operator.

:::

**Tag the Repository**

Once you are satisfied with your operator's development and testing, you can tag your repository. Tagging will trigger the Release GitHub workflow, which will create a release for your operator.

```bash
git tag v1.0.0
git push origin v1.0.0
```

**Install the operator**

If you want to install it directly from `Tercen`, you will need to 
[create a release in GitHub](https://help.github.com/en/github/administering-a-repository/managing-releases-in-a-repository). All the operators are version controlled.

All __operators__ who are on a git repository are installable, 
only the git URL and a tag version number is required for a researcher to
install it in Tercen.

## Conclusion {-}

Congratulations! You have successfully developed and deployed an operator for Tercen.
By following these steps, you can create custom data processing operators to extend the functionality 
of Tercen and streamline your data analysis workflows. The beauty of Tercen is that you can choose 
the programming language that best fits your needs - whether that's R for statistical analysis 
or Python for machine learning and data science workflows.

Remember to consult the Tercen documentation for more details and advanced features. Happy coding!

# Improving an operator

Now that we have deployed our operator for Tercen, we can always improve it! In this chapter we will see how to catch errors, add input parameters (_properties_), and prepare testing for our operators.

## Error catching {-}

### Check the presence of input projection {-}

For operators that require specific projections, we can check if both _x_ and _y_ axes have been set in the projection, and return an error message to help the user.

::: {.panel-tabset}

### R

```r
ctx <- tercenCtx()

if(inherits(try(ctx$select(".x")), 'try-error')) stop("x axis is missing.")
if(inherits(try(ctx$select(".y")), 'try-error')) stop("y axis is missing.")
```

### Python

```python
try:
    tercenCtx.select(['.x'])
except:
    raise ValueError("x axis is missing.")

try:
    tercenCtx.select(['.y'])
except:
    raise ValueError("y axis is missing.")
```

:::

### Catch errors in key processes {-}

We can also use error handling to catch potential errors in key processes of our operator. In our linear regression example, we can catch errors occurring while running the regression function and return NaN values when the model fails.

::: {.panel-tabset}

### R

```r
do.lm <- function(df) {
  out <- data.frame(
    .ri = df$.ri[1],
    .ci = df$.ci[1],
    intercept = NaN,
    slope = NaN
  )
  mod <- try(lm(.y ~ .x, data = df))    # try-catch
  if(!inherits(mod, 'try-error')) {     # get coefficients if lm ran successfully
    out$intercept <- mod$coefficients[1]
    out$slope <- mod$coefficients[2]
  }
  return(out)
}
```

### Python

```python
def do_lm(group_df):
    """Perform linear regression on a group with error handling"""
    try:
        # Get x and y values
        x = group_df['.x'].to_numpy().reshape(-1, 1)
        y = group_df['.y'].to_numpy()
        
        # Check if we have enough data points
        if len(x) < 2:
            raise ValueError("Not enough data points")
        
        # Fit linear regression
        model = LinearRegression()
        model.fit(x, y)
        
        return pl.DataFrame({
            '.ri': [group_df['.ri'][0]],
            '.ci': [group_df['.ci'][0]],
            'intercept': [model.intercept_],
            'slope': [model.coef_[0]]
        })
    except Exception as e:
        # Return NaN if model fails
        print(f"Model failed for group: {e}")
        return pl.DataFrame({
            '.ri': [group_df['.ri'][0]],
            '.ci': [group_df['.ci'][0]],
            'intercept': [np.nan],
            'slope': [np.nan]
        })
```

:::

## Adding properties {-}

Tercen operators can take input parameters (called _properties_). They can be of different types (boolean, enumerated, numeric).

As an example, let's see how to add a property to decide whether to omit the intercept in a linear regression model or not.

### Modify the operator's JSON file to add properties {-}

For each property, we have to set values to different attributes:

* `kind`: property kind (`BooleanProperty`, `DoubleProperty`, or `EnumeratedProperty`)
* `name`: name that will be displayed in Tercen
* `defaultValue`: default value taken by the property
* `description`: description to be displayed in Tercen

Example `operator.json` with a boolean property:

```json
{
  "name": "Linear regression",
  "description": "Returns the intercept and slope of a linear regression in a cell",
  "tags": ["linear model"],
  "authors": ["tercen"],
  "urls": ["https://github.com/username/lm_operator"],
  "properties": [
    {
      "kind": "BooleanProperty",
      "name": "intercept.omit",
      "defaultValue": false,
      "description": "A logical value indicating whether the intercept should be omitted in the model."
    }
  ]
}
```

### Use the property in the operator code {-}

This property can be called in the operator code as follows:

::: {.panel-tabset}

### R

```r
intercept.omit <- as.logical(ctx$op.value('intercept.omit'))
if(intercept.omit) {
  mod <- try(lm(.y ~ .x - 1, data = df))
} else {
  mod <- try(lm(.y ~ .x, data = df))
}
```

### Python

```python
# Get the property value
intercept_omit = tercenCtx.op.value('intercept.omit', False)

# Use the property in your calculation
if intercept_omit:
    # Fit model without intercept
    model = LinearRegression(fit_intercept=False)
else:
    # Fit model with intercept
    model = LinearRegression(fit_intercept=True)

model.fit(x, y)
```

:::

## Preparing operator testing {-}

It's always good to prepare some tests that could be run when a new version of Tercen is released.

To include a test, you need to __create a `test` subdirectory__ in your project directory. It must include:

* a test __input file__
* an expected __output file__
* a __`JSON` file__ containing information about the test

### Creating test data {-}

::: {.panel-tabset}

### R

```r
# Simulate tercen input based on the CO2 dataset 
# with an x and y-axis, rows and columns
data(CO2)
df <- data.frame(.x = CO2$conc, .y = CO2$uptake, .ri = CO2$Plant, .ci = CO2$Treatment)

# Run the do.lm() function created above to generate the expected output
out <- df %>% select(.ci, .ri, .x, .y) %>%
  group_by(.ri, .ci) %>%
  do(do.lm(.))

# write input and expected output in the test subdirectory
dir.create("test", showWarnings = FALSE)
write.csv(df, file="./test/input.csv", row.names = FALSE, quote = FALSE)
write.csv(out, file="./test/output.csv", row.names = FALSE, quote = FALSE)
```

### Python

```python
import pandas as pd
import numpy as np

# Create test data
np.random.seed(42)
n_groups = 4
n_points = 10

test_data = []
for ri in range(2):
    for ci in range(2):
        x_vals = np.linspace(1, 10, n_points)
        y_vals = 2 * x_vals + 1 + np.random.normal(0, 0.5, n_points)
        
        for i in range(n_points):
            test_data.append({
                '.x': x_vals[i],
                '.y': y_vals[i],
                '.ri': ri,
                '.ci': ci
            })

df = pd.DataFrame(test_data)

# Generate expected output using your function
# ... (run your operator function)

# Save test files
import os
os.makedirs("test", exist_ok=True)
df.to_csv("./test/input.csv", index=False)
# expected_output.to_csv("./test/output.csv", index=False)
```

:::

### Create the test JSON file {-}

Now that we have our input and output files, we can __create the `JSON` file__ that shall include the following information:

```json
{
  "kind": "OperatorUnitTest",
  "name": "testlm1",
  "namespace": "test",
  "inputDataUri": "input.csv",
  "outputDataUri": ["output.csv"],
  "columns": [],
  "rows": [],
  "colors": [],
  "labels": [],
  "yAxis": ".y",
  "xAxis": ".x"
}
```

The `name` attribute is free. Input and output test files names must be assigned to the `inputDataUri` and `outputDataUri`, respectively. Variable names of the input file must be assigned to the `columns`, `rows`, `colors`, `labels`, `yAxis`, `xAxis` attributes. In our case, `colors` and `labels` are left empty as they are not part of our input.
